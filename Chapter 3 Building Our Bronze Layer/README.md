# Chapter 3: Building Our Bronze Layer 

Here is what you will learn as part of this chapter:

1. Revising the Medallion architecture pattern
2. Transforming data to Delta with Auto Loader
3. Delta Live Tables starting with Bronze
4. Maintaining and optimizing Delta Tables
5. Applying our learning

## Technical requirements 

Databricks ML Runtime includes several pre-installed libraries useful for machine learning and data science projects. For this reason, we will be using clusters with an [ML Runtime](https://docs.databricks.com/runtime/mlruntime.html#introduction-to-databricks-runtime-for-machine-learning).

  
## Links

**Further Reading**
- [Use liquid clustering for Delta tables](https://docs.databricks.com/en/delta/clustering.html)
- [Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Delta Live Tables](https://docs.databricks.com/en/delta-live-tables/index.html)
- [DLT Databricks Demo](https://www.databricks.com/resources/demos/tutorials/lakehouse-platform/full-delta-live-table-pipeline))
- [AutoLoader options](https://docs.databricks.com/ingestion/auto-loader/options.html)
- [Schema evolution with Auto Loader](https://docs.databricks.com/ingestion/auto-loader/schema.html#configure-schema-inference-and-evolution-in-auto-loader)
- [Common loading patterns with Auto Loader](https://docs.databricks.com/ingestion/auto-loader/patterns.html)
- [Stream processing with Apache Kafka and Databricks](https://docs.databricks.com/structured-streaming/kafka.html)
- [Blog: Context length in LLMs: All you need to know](https://agi-sphere.com/context-length/)
- [How We Performed ETL on One Billion Records For Under $1 With Delta Live Tables](https://www.databricks.com/blog/2023/04/14/how-we-performed-etl-one-billion-records-under-1-delta-live-tables.html)
- [Create tables - Managed vs External](https://docs.databricks.com/en/data-governance/unity-catalog/create-tables.html#create-tables)
- [Take full advantage of the auto-tuning available](https://docs.databricks.com/delta/tune-file-size.html#configure-delta-lake-to-control-data-file-size)
- [Import Python modules from Databricks repos](https://docs.databricks.com/en/delta-live-tables/import-workspace-files.html)
- [Deletion Vectors](https://docs.databricks.com/en/delta/deletion-vectors.html)
- [Databricks ML Runtime](https://docs.databricks.com/runtime/mlruntime.html#introduction-to-databricks-runtime-for-machine-learning)
- [Cluster advanced options](https://docs.databricks.com/en/clusters/configure.html#spark-configuration)
- [Deploy provisioned throughput Foundation Model APIs](https://docs.databricks.com/en/machine-learning/foundation-models/deploy-prov-throughput-foundation-model-apis.html)
- [Scaling Deep Learning Using Delta Lake Storage Format on Databricks](https://www.databricks.com/dataaisummit/session/scaling-deep-learning-using-delta-lake-storage-format-databricks/)
- [DeltaTorchLoader](https://github.com/delta-incubator/deltatorch)

