# Chapter 7: Productionizing Machine Learning

**Here is what you will learn as part of this chapter:**
1. Registering your model in the UC Model Registry
2. Deploying your model - Inference & Serving
3. Automating the ML Lifecycle
4. Applying our learning

## Technical requirements 

Here are the technical requirements needed to complete the hands-on examples in this chapter:
- [On-demand features require the use of DBR ML 13.1 or higher.
- [Python UDFs](https://docs.databricks.com/en/udf/unity-catalog.html) are created and governed in UC; hence, Unity Catalog must be enabled for the workspace.
  
## Links

**In the chapter**
- [MLFLow Model Registry Webhooks on Databricks](https://docs.databricks.com/en/mlflow/model-registry-webhooks.html)

**Further Reading**
- [The big book of machine learning use case](https://www.databricks.com/resources/ebook/big-book-of-machine-learning-use-cases)
- [Databricks Model Serving](https://www.databricks.com/blog/2023/03/07/announcing-general-availability-databricks-model-serving.html)
- [Model Evaluation in MLFLow](https://www.databricks.com/blog/2022/04/19/model-evaluation-in-mlflow.html)
- [The big book of MLOps](https://www.databricks.com/resources/ebook/the-big-book-of-mlops)
- [Databricks Asset Bundles - Programmatically define, deploy, and run Databricks jobs, Delta Live Tables pipelines, and MLOps Stacks using CI/CD best practices and workflows](https://docs.databricks.com/en/dev-tools/bundles/index.html)
- [CI/CD workflows with Git and Databricks Repos - Use GitHub and Databricks Repos for source control and CI/CD workflows](https://docs.databricks.com/en/repos/ci-cd-techniques-with-repos.html)
- [Continuous integration and delivery using GitHub Actions - Build a CI/CD workflow on GitHub that uses GitHub Actions developed for Databricks](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-github.html)
- [CI/CD with Jenkins on Databricks - Develop a CI/CD pipeline for Databricks that uses Jenkins](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-jenkins.html)
- [Orchestrate Databricks jobs with Apache Airflow - Manage and schedule a data pipeline that uses Apache Airflow](https://docs.databricks.com/en/workflows/jobs/how-to/use-airflow-with-jobs.html)
- [Service principals for CI/CD - ​​Use service principals instead of users with CI/CD systems](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-sp.html)
